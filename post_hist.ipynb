{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post histogram maker\n",
    "\n",
    "\n",
    "This notebook helps to make plots using the pre-processed data, which includes\n",
    " - data/MC comparison plots under some given event selection;\n",
    " - Xbb/cc signal and proxy jets comparison plots on various jet observables;\n",
    " - other comparisons.\n",
    "\n",
    "\n",
    "The data anlaysis is backed by `ak-array` data stucture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, TreeMakerSchema, BaseSchema\n",
    "import awkward1 as ak\n",
    "import uproot4 as uproot\n",
    "import uproot3\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_hist, plot_hist\n",
    "from cycler import cycler\n",
    "import boost_histogram as bh\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# mpl.use('AGG') # no rendering plots in the window\n",
    "\n",
    "import mplhep as hep\n",
    "use_helvet = True  ## true: use helvetica for plots, make sure the system have the font installed\n",
    "if use_helvet:\n",
    "    CMShelvet = hep.style.CMS\n",
    "    CMShelvet['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "    plt.style.use(CMShelvet)\n",
    "else:\n",
    "    plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import get_hist, plot_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the config.yml\n",
    "import yaml\n",
    "with open('cards/config_cc_ak15_std.yml') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files\n",
    "\n",
    "Load the ROOT files into lazy awkward arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = config['year']\n",
    "\n",
    "lumi = {2016: 35.92, 2017: 41.53, 2018: 59.74}\n",
    "\n",
    "read_sample_list_map = {\n",
    "    'qcd-mg-noht': 'mc/qcd-mg_tree.root',\n",
    "    'qcd-herwig-noht': 'mc/qcd-herwig_tree.root',\n",
    "    'top-noht': 'mc/top_tree.root',\n",
    "    'v-qq-noht': 'mc/v-qq_tree.root',\n",
    "    'jetht-noht': 'data/jetht_tree.root',\n",
    "}\n",
    "if config['samples']['use_bflav']:\n",
    "    read_sample_list_map['qcd-mg-bflav-noht'] = 'mc/qcd-mg-bflav_tree.root'\n",
    "\n",
    "## Read the root file into lazy awkward arrays\n",
    "arr = {}\n",
    "sample_prefix = f\"{config['samples']['sample_prefix']}_{year}\"\n",
    "for sam in read_sample_list_map:\n",
    "    arr[sam] = NanoEventsFactory.from_root(f'{sample_prefix}/{read_sample_list_map[sam]}', schemaclass=BaseSchema).events()\n",
    "\n",
    "## Store the branch names\n",
    "stored_branches = {}\n",
    "for sam in read_sample_list_map:\n",
    "    stored_branches[sam] = ak.fields(arr[sam])\n",
    "store_name = f\"{config['samples']['name']}_SF{config['year']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load backup pickels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch variables from the backup file\n",
    "def load_backup_array(backup_name, read_sample_list_map):\n",
    "    r\"\"\"Load newly stored variables to the awkwary array list.\n",
    "    \n",
    "    Arguments:\n",
    "        backup_name: name of backup folder\n",
    "        read_sample_list: sample list to read.\n",
    "    \"\"\"\n",
    "\n",
    "    import pickle\n",
    "    for sam in os.listdir(f'prep/{backup_name}'):\n",
    "        if sam in read_sample_list_map:\n",
    "            for var in os.listdir(f'prep/{backup_name}/{sam}'):\n",
    "                if var.startswith('.'):\n",
    "                    continue\n",
    "                if var == 'maskdict':\n",
    "                    arr[sam].maskdict = {}\n",
    "                    with open(f'prep/{backup_name}/{sam}/maskdict', 'rb') as f:\n",
    "                        arr[sam].maskdict = pickle.load(f)\n",
    "                    print('loading...', sam, 'maskdict', arr[sam].maskdict.keys())\n",
    "                else:\n",
    "                    with open(f'prep/{backup_name}/{sam}/{var}', 'rb') as f:\n",
    "                        arr[sam][var] = pickle.load(f)\n",
    "                    print('loading...', sam, var)\n",
    "            if sam != 'jetht-noht':\n",
    "                arr['subst_'+sam] = arr[sam] # make a reference\n",
    "        elif not sam.startswith('.') and os.path.isfile(f'prep/{backup_name}/{sam}'):\n",
    "            with open(f'prep/{backup_name}/{sam}', 'rb') as f:\n",
    "                arr[sam] = pickle.load(f)\n",
    "            print('loading...', sam)\n",
    "\n",
    "load_backup_array(store_name, read_sample_list_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_expr(ak_array, expr, mask=None):\n",
    "    \"\"\"A function that can do `eval` to the awkward array, immitating the behavior of `eval` in pandas.\"\"\"\n",
    "    \n",
    "    def get_variable_names(expr, exclude=['awkward', 'ak', 'np', 'numpy', 'math']):\n",
    "        \"\"\"Extract variables in the expr\"\"\"\n",
    "        import ast\n",
    "        root = ast.parse(expr)\n",
    "        return sorted({node.id for node in ast.walk(root) if isinstance(node, ast.Name) and not node.id.startswith('_')} - set(exclude))\n",
    "\n",
    "    tmp = {k:ak_array[k] if mask is None else ak_array[k].mask[mask] for k in get_variable_names(expr)}\n",
    "    tmp.update({'math': math, 'numpy': np, 'np': np, 'awkward': ak, 'ak': ak})\n",
    "#     print('eval expr: ', expr, '\\nvars', get_variable_names(expr))\n",
    "    return eval(expr, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and(arr, mask_list):\n",
    "    \"\"\"Calculate AND of given mask list\"\"\"\n",
    "    return np.logical_and.reduce([arr.maskdict[mask] for mask in mask_list])\n",
    "\n",
    "def concat_array(arrdict, expr, sam_list, filter_list):\n",
    "    \"\"\"Concatenate the awkward arrays passing the given filter list\"\"\"\n",
    "    if not isinstance(sam_list, list):\n",
    "        sam_list = [sam_list]\n",
    "    return np.concatenate([\n",
    "        np.array(eval_expr(arrdict[sam], expr)[mask_and(arrdict[sam], filter_list)]) for sam in sam_list\n",
    "    ])\n",
    "\n",
    "def mask_and_fj12(arr, mask_list):\n",
    "    \"\"\"Comibne `mask_and` result for fj_1 and fj_2\"\"\"\n",
    "    mask_list_fj1 = [ele.replace('fj_x', 'fj_1') for ele in mask_list]\n",
    "    mask_list_fj2 = [ele.replace('fj_x', 'fj_2') for ele in mask_list]\n",
    "    return np.concatenate([mask_and(arr, mask_list_fj1), mask_and(arr, mask_list_fj2)])\n",
    "\n",
    "def concat_array_fj12(arrdict, expr, sam_list, filter_list):\n",
    "    \"\"\"Comibne `concat_array` result for fj_1 and fj_2\"\"\"\n",
    "    filter_list_fj1 = [ele.replace('fj_x', 'fj_1') for ele in filter_list]\n",
    "    filter_list_fj2 = [ele.replace('fj_x', 'fj_2') for ele in filter_list]\n",
    "    return np.concatenate([concat_array(arrdict, expr.replace('fj_x', 'fj_1'), sam_list, filter_list_fj1), \n",
    "                           concat_array(arrdict, expr.replace('fj_x', 'fj_2'), sam_list, filter_list_fj2)])\n",
    "\n",
    "def calc_rwgt_akarray(arr, rwgt_edge, rwgt):\n",
    "    \"\"\"Calculate the weight ak-array based on the value ak-array of the reweight variable\"\"\"\n",
    "    arr_out = (arr<rwgt_edge[0])*rwgt[0]\n",
    "    for i in range(len(rwgt_edge)-1):\n",
    "        arr_out = arr_out + ((arr>=rwgt_edge[i]) & (arr<rwgt_edge[i+1]))*rwgt[i+1]\n",
    "    arr_out = arr_out + (arr>=rwgt_edge[-1])*rwgt[-1]\n",
    "    return arr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "# Data/MC comparison plots\n",
    "\n",
    "Based on the ak-array dict `arr`, this section aims to make data and MC plots, while MC is categorized into three flavors: C/B/L.\n",
    "With the universial make_data_mc_plots function, one can make specify any final selection, any sample list to produce the standard hist+ratio plot.\n",
    "\n",
    "The below recipe can make a default set of plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ================ configuration  ===================\n",
    "\n",
    "def make_config_dm(sl_dm, wgtstr_dm):\n",
    "    return {\n",
    "        'data':  ('Data',       'jetht-noht',      '1.0',    ''      ),\n",
    "        'flvB':  ('MC (flvB)', sl_dm[:-1],        wgtstr_dm,   'fj_x_nbhadrons>=1'  ),\n",
    "        'flvC':  ('MC (flvC)', sl_dm[:-1],        wgtstr_dm,   '(fj_x_nbhadrons==0) & (fj_x_nchadrons>=1)'  ),\n",
    "        'flvL':  ('MC (flvL)', sl_dm[:-1],        wgtstr_dm,   '(fj_x_nbhadrons==0) & (fj_x_nchadrons==0)'  ),\n",
    "    }\n",
    "categories_dm = ['flvL', 'flvB', 'flvC', 'data']\n",
    "\n",
    "bininfo_dm = [ #(savename, vname, nbin, xmin, xmax, label)\n",
    "    ('ht', 'ht', 60, 0, 3000, r'$H_{T}$ [GeV]'),\n",
    "#     ('fj_x_pt', 'fj_x_pt', 100, 0, 2500, r'$p_{T}(AK15)$ [GeV]'),\n",
    "#     ('fj_x_eta', 'fj_x_eta', 20, -2.5, 2.5, r'$\\eta(AK15)$'),\n",
    "#     ('fj_x_sdmass', 'fj_x_sdmass', 15, 50, 200, r'$m_{SD}(AK15)$ [GeV]'),\n",
    "#     ('fj_x_sfBDT', 'fj_x_sfBDT', 50, 0.5, 1, r'$sfBDT(AK15)$'),\n",
    "\n",
    "#     (\"fj_x_mSV12_dxysig\", \"fj_x_mSV12_dxysig\", 50, 0, 20, r'$log(m_{SV1,d_{xy}sig\\,max}\\; /GeV)$'),\n",
    "#     (\"fj_x_btagcsvv2\", \"fj_x_btagcsvv2\", [0,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.98,0.99,0.995,1], None, None, r'$CSVv2$'),\n",
    "#     (\"fj_x_mSV12_ptmax_log\", \"fj_x_mSV12_ptmax_log\", [-0.4,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,2.5,3.2,3.9], None, None, r'$log(m_{SV1,p_{T}\\,max}\\; /GeV)$'),\n",
    "#     (\"fj_x_mSV12_dxysig_log\", \"fj_x_mSV12_dxysig_log\", [-0.8,-0.4,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,2.5,3.2], None, None, r'$log(m_{SV1,d_{xy}sig\\,max}\\; /GeV)$'),\n",
    "]\n",
    "bininfo_dm += [\n",
    "    (config['tagger']['var'], config['tagger']['var'], 100, 0, 1, config['tagger']['var'].replace('fj_x_','')),\n",
    "#     (config['tagger']['var'], config['tagger']['var'], 50, 0.8, 1, config['tagger']['var'].replace('fj_x_','')+'-u'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ================ slim on tagger, sfBDT, then make data/MC plots ===================\n",
    "\n",
    "import seaborn as sns\n",
    "def set_sns_color(*args):\n",
    "    sns.palplot(sns.color_palette(*args))\n",
    "    sns.set_palette(*args)\n",
    "\n",
    "def calc_custom_masks(sl_dm, filter_list, config_dm):\n",
    "    for sam in sl_dm:\n",
    "        ext_filter_list = [config_dm[s][-1] for s in config_dm if (sam in config_dm[s][1] or config_dm[s][1]==sam) and config_dm[s][-1] != '']\n",
    "        for mask in filter_list + ext_filter_list:\n",
    "            for i in '12':\n",
    "#                 if mask.replace('fj_x', f'fj_{i}') not in arr[sam].maskdict.keys():\n",
    "                print('new mask calculated (fj_x -> fj_1/2): ', sam, mask.replace('fj_x', f'fj_{i}'))\n",
    "                if 'fj_x_pt' in mask:\n",
    "                    import re\n",
    "                    ptmin, ptmax = re.findall('fj_x_pt(\\S+)to(\\S+)', mask)[0]\n",
    "                    ptmax = '100000' if ptmax=='Inf' else ptmax\n",
    "                    arr[sam].maskdict[mask.replace('fj_x', f'fj_{i}')] = eval_expr(arr[sam], f'(fj_{i}_pt>={ptmin}) & (fj_{i}_pt<{ptmax})')\n",
    "                else:\n",
    "                    arr[sam].maskdict[mask.replace('fj_x', f'fj_{i}')] = eval_expr(arr[sam], mask.replace('fj_x', f'fj_{i}'))\n",
    "\n",
    "def make_data_mc_plots(sl_dm, config_dm, filter_list, prefix, **kwargs):\n",
    "    r\"\"\"To make standard hist+ratio plots based on the sample list and the final selection\n",
    "    Arguments:\n",
    "        sl_dm: sample list\n",
    "        config_dm: configuration set for each categories in the plots, in the dict format. name: (label, sample/sample list, weight string, cat selection)\n",
    "        filter_list: keys of maskdict. The corresponding selections are used to produce the plots\n",
    "        prefix: prefix string used in the output plot title\n",
    "        kwargs: includes further KDE-related variables\n",
    "    \"\"\"\n",
    "    \n",
    "    calc_custom_masks(sl_dm, filter_list, config_dm)\n",
    "    result_dic = {savename: {} for savename, _, _, _, _, _ in bininfo_dm}\n",
    "    for savename, vname, nbin, xmin, xmax, vlabel in bininfo_dm:\n",
    "        if 'plot_vars' in kwargs and savename not in kwargs['plot_vars']:\n",
    "            continue\n",
    "        if not isinstance(nbin, int):\n",
    "            edges, xmin, xmax, nbin = nbin, min(nbin), max(nbin), len(nbin)\n",
    "        else:\n",
    "            edges = np.linspace(xmin, xmax, nbin+1)\n",
    "\n",
    "        label, hdm = {}, {}\n",
    "        underflow = False if vlabel[-2:] in ['-u','-a'] else True\n",
    "        overflow  = False if vlabel[-2:] in ['-o','-a'] else True\n",
    "        if vlabel[-2:] in ['-u','-o','-a']:\n",
    "            vlabel = vlabel[:-2]\n",
    "        \n",
    "        if 'g_do_kde_vars' in kwargs and savename in kwargs['g_do_kde_vars'] and kwargs['g_do_kde_vars'][savename]==True:\n",
    "            g_do_kde_vars = True\n",
    "            kde = {}\n",
    "        else:\n",
    "            g_do_kde_vars = False\n",
    "        \n",
    "        ## Loop over categories to extract the hist for each flavor and data\n",
    "        for cat in categories_dm:\n",
    "            lab, sam, wgt, sel = config_dm[cat]\n",
    "            label[cat] = lab\n",
    "            if cat != 'data':\n",
    "                _content = concat_array_fj12(arr, expr=vname, sam_list=sam, filter_list=['fj_x_base']+filter_list+([sel] if sel!='' else []))\n",
    "                _weights = concat_array_fj12(arr, expr=wgt,   sam_list=sam, filter_list=['fj_x_base']+filter_list+([sel] if sel!='' else []))\n",
    "                import pickle\n",
    "                with open(f'.roofit_{cat}.pickle', 'wb') as fw:\n",
    "                    pickle.dump({'content':_content, 'weights':_weights}, fw)\n",
    "                hdm[cat] = get_hist(_content, bins=edges, weights=_weights, underflow=underflow, overflow=overflow)\n",
    "                if g_do_kde_vars:\n",
    "                    from scipy.stats import gaussian_kde\n",
    "                    from scipy import integrate\n",
    "                    import multiprocessing\n",
    "                    if 'custom_kde' in kwargs.keys() and savename in kwargs['custom_kde']:\n",
    "                        kde[cat] = kwargs['custom_kde'][savename][cat]\n",
    "                        kde_int_res = [\n",
    "                                integrate.quad(kde[cat][0], -np.inf if (i==0 and underflow) else edges[i], \n",
    "                                                  +np.inf if (i==len(edges)-1 and overflow) else edges[i+1]) for i in range(len(edges)-1)]\n",
    "                    else:\n",
    "                        kdetmp = gaussian_kde(_content, weights=np.clip(_weights, 0, np.inf))\n",
    "                        if 'g_custom_kde_bw' in kwargs.keys() and savename in kwargs['g_custom_kde_bw']:\n",
    "                            kdetmp = gaussian_kde(_content, weights=np.clip(_weights, 0, np.inf), bw_method=kdetmp.factor/kwargs['g_custom_kde_bw'][savename])\n",
    "                        kde[cat] = (kdetmp, _weights.sum())\n",
    "                        kde_int_res = [(kde[cat][0].integrate_box_1d(-np.inf if (i==0 and underflow) else edges[i], +np.inf if (i==len(edges)-1 and overflow) else edges[i+1]), 0.) for i in range(len(edges)-1)]\n",
    "                    hdm[cat+'_kde'] = hdm[cat].copy()\n",
    "                    hdm[cat+'_kde'].view(flow=True).value = np.array([kde_int_res[i][0] for i in range(len(edges)-1)]) * kde[cat][1]\n",
    "                    hdm[cat+'_kde'].view(flow=True).variance = np.zeros(len(edges)-1)\n",
    "                        \n",
    "            else: ## is data: no sel, weight=1\n",
    "                _content = concat_array_fj12(arr, expr=vname, sam_list=sam, filter_list=['fj_x_base']+filter_list)\n",
    "                _weights = np.ones_like(_content)\n",
    "                hdm[cat] = get_hist(_content, bins=edges, weights=_weights, underflow=underflow, overflow=overflow)\n",
    "                \n",
    "        cat_sufs = ['']\n",
    "        if g_do_kde_vars:\n",
    "            cat_sufs += ['_kde']\n",
    "        for cat_suf in cat_sufs:\n",
    "            ## Draw the standard hist_ratio plot\n",
    "            set_sns_color('cubehelix_r', 3) ## set the color palette\n",
    "            f = plt.figure(figsize=(12,12))\n",
    "            gs = mpl.gridspec.GridSpec(2, 1, height_ratios=[3, 1], hspace=0.05) \n",
    "            \n",
    "            ## Upper histogram panel\n",
    "            ax = f.add_subplot(gs[0])\n",
    "            hep.cms.label(data=True, paper=False, year=2016, ax=ax, rlabel=r'%s $fb^{-1}$ (13 TeV)'%lumi[year], fontname='sans-serif')\n",
    "            ax.set_xlim(xmin, xmax); ax.set_xticklabels([]); ax.set_ylabel('Events / bin', ha='right', y=1.0)\n",
    "\n",
    "            plot_hist([hdm[cat+cat_suf] for cat in categories_dm if cat!='data'], bins=edges, label=[label[cat] for cat in categories_dm if cat!='data'], histtype='fill', edgecolor='k', linewidth=1, stack=True) ## draw stacked bkg\n",
    "            cats_mc = list(set(categories_dm) - set(['data']))\n",
    "            hdm_add = hdm[cats_mc[0]+cat_suf].copy()\n",
    "            for cat in cats_mc[1:]:\n",
    "                hdm_add += hdm[cat+cat_suf]\n",
    "            bkgtot, bkgtot_err = hdm_add.view(flow=True).value, np.sqrt(hdm_add.view(flow=True).variance)\n",
    "            ax.fill_between(edges, (bkgtot-bkgtot_err).tolist()+[0], (bkgtot+bkgtot_err).tolist()+[0], label='BKG unce.', step='post', hatch='///', edgecolor='darkblue', facecolor='none', linewidth=0) ## draw bkg unce.\n",
    "            plot_hist(hdm['data'], bins=edges, label='Data', histtype='errorbar', color='k', markersize=15, elinewidth=1.5) ## draw data\n",
    "            ax.set_yscale('log'); ax.set_ylim(1e-1, ax.get_ylim()[1])\n",
    "\n",
    "            ax.legend()\n",
    "            # ax.legend(loc='upper left'); ax.set_ylim(0, 1.4*ax.get_ylim()[1])\n",
    "            \n",
    "            ## Ratio panel\n",
    "            ax1 = f.add_subplot(gs[1]); ax1.set_xlim(xmin, xmax); ax1.set_ylim(0.001, 1.999)\n",
    "            ax1.set_xlabel(vlabel, ha='right', x=1.0); ax1.set_ylabel('Data / MC', ha='center')\n",
    "            ax1.plot([xmin,xmax], [1,1], 'k'); ax1.plot([xmin,xmax], [0.5,0.5], 'k:'); ax1.plot([xmin,xmax], [1.5,1.5], 'k:')\n",
    "\n",
    "            hr = hdm['data'].view(flow=True).value / hdm_add.view(flow=True).value\n",
    "            # hr_err = hr * np.sqrt(hdm['data'].view(flow=True).variance/(hdm['data'].view(flow=True).value**2) + hdm_add.view(flow=True).variance/(hdm_add.view(flow=True).value**2))\n",
    "            hr_dataerr = hr * np.sqrt(hdm['data'].view(flow=True).variance/(hdm['data'].view(flow=True).value**2))\n",
    "            ax1.fill_between(edges, ((bkgtot-bkgtot_err)/bkgtot).tolist()+[0], ((bkgtot+bkgtot_err)/bkgtot).tolist()+[0], step='post', hatch='///', edgecolor='darkblue', facecolor='none', linewidth=0) ## draw bkg unce.\n",
    "            hep.histplot(np.nan_to_num(hr, nan=-1), bins=edges, yerr=np.nan_to_num(hr_dataerr), histtype='errorbar', color='k', markersize=15, elinewidth=1) ## draw data in ratio plot\n",
    "\n",
    "            filter_list_str = '_'.join(filter_list)\n",
    "            print('save plot: ', f'plots/{g_dirname}_{year}/{prefix}__{filter_list_str}__{savename}{cat_suf}.png/pdf')\n",
    "            plt.savefig(f'plots/{g_dirname}_{year}/{prefix}__{filter_list_str}__{savename}{cat_suf}.png')\n",
    "            plt.savefig(f'plots/{g_dirname}_{year}/{prefix}__{filter_list_str}__{savename}{cat_suf}.pdf')\n",
    "\n",
    "        ## kde/orig comparison plots\n",
    "        if g_do_kde_vars:\n",
    "            mpl.rcParams['axes.prop_cycle'] = cycler(color=['blue', 'red', 'green'])\n",
    "            f, ax = plt.subplots(figsize=(12,12))\n",
    "            hep.cms.label(data=False, paper=False, year=year, ax=ax, rlabel=r'%s $fb^{-1}$ (13 TeV)'%lumi[year], fontname='sans-serif')\n",
    "            x_contin = np.linspace(xmin, xmax, 201)\n",
    "            bin_width = edges[int(nbin/2)+1] - edges[int(nbin/2)]\n",
    "            for cat, color in zip(['flvC', 'flvB', 'flvL'], ['blue', 'red', 'green']):\n",
    "                lab, sam, wgt, sel = config_dm[cat]\n",
    "                ax.plot(x_contin, kde[cat][0](x_contin) * kde[cat][1] * bin_width, label=lab+' KDE', linestyle=':', color=color)\n",
    "            for cat, color in zip(['flvC', 'flvB', 'flvL'], ['blue', 'red', 'green']):\n",
    "                lab, sam, wgt, sel = config_dm[cat]\n",
    "                hep.histplot(hdm[cat+'_kde'].view(flow=True).value, bins=edges, label=lab+' KDE integral', linestyle='--', color=color)\n",
    "                plot_hist(hdm[cat], bins=edges, label=lab, normed=False, color=color)\n",
    "            ax.set_xlim(xmin, xmax); ax.set_xlabel(vlabel, ha='right', x=1.0); ax.set_ylabel('A.U.', ha='right', y=1.0); ax.legend()\n",
    "\n",
    "            filter_list_str = '_'.join(filter_list)\n",
    "            plt.savefig(f'plots/{g_dirname}_{year}/{prefix}:kde_shape__{filter_list_str}__{savename}.png')\n",
    "            plt.savefig(f'plots/{g_dirname}_{year}/{prefix}:kde_shape__{filter_list_str}__{savename}.pdf')\n",
    "            \n",
    "\n",
    "g_do_kde_vars = {'fj_x_btagcsvv2':True, 'fj_x_mSV12_ptmax_log':True, 'fj_x_mSV12_dxysig_log':True}\n",
    "g_custom_kde_bw = {'fj_x_btagcsvv2':15, 'fj_x_mSV12_ptmax_log':4, 'fj_x_mSV12_dxysig_log':4}\n",
    "\n",
    "g_dirname = config['routine_name']+'_datamc'\n",
    "if not os.path.exists(f'plots/{g_dirname}_{year}'):\n",
    "    os.makedirs(f'plots/{g_dirname}_{year}')\n",
    "\n",
    "for ptrange in config['pt_range']['range']:\n",
    "    ptlab = f'pt{ptrange[0]}to{ptrange[1]}'\n",
    "    bdt_seq = arr[f\"bdt_seq_{config['pt_range']['name']}__{config['main_analysis_tree']['name']}\"][(ptrange[0], ptrange[1])]\n",
    "    bdt_cent = bdt_seq[int((len(bdt_seq)-1)/2)]\n",
    "    tagger_wp = sorted([rg[0] for rg in config['tagger']['working_points']['range'].values()])\n",
    "\n",
    "    ## 1. With MadGraph sample list\n",
    "    wgtstr_dm = f'genWeight*xsecWeight*puWeight*{lumi[year]}*fj_x_htwgt'\n",
    "    sl_dm = ['subst_qcd-mg-noht', 'subst_top-noht', 'subst_v-qq-noht', 'jetht-noht']\n",
    "    make_data_mc_plots(sl_dm, make_config_dm(sl_dm, wgtstr_dm), filter_list=[f'fj_x_{ptlab}', 'fj_x_sfBDT>0.5'], prefix='mg')\n",
    "    make_data_mc_plots(sl_dm, make_config_dm(sl_dm, wgtstr_dm), filter_list=[f'fj_x_{ptlab}', f'fj_x_sfBDT>{bdt_cent:.3f}'], prefix='mg')\n",
    "    make_data_mc_plots(sl_dm, make_config_dm(sl_dm, wgtstr_dm), filter_list=[f'fj_x_{ptlab}', f'fj_x_sfBDT>{bdt_cent:.3f}', f\"{config['tagger']['var']}>{tagger_wp[-1]}\"], prefix='mg')\n",
    "\n",
    "#     ## 2. With MadGraph sample list, while using the optional MC-to-data reweight scheme (on pT)\n",
    "#     wgtstr_dm = f'genWeight*xsecWeight*puWeight*{lumi[year]}*fj_x_ad_ptwgt'\n",
    "#     sl_dm = ['subst_qcd-mg-noht', 'subst_top-noht', 'subst_v-qq-noht', 'jetht-noht']\n",
    "#     make_data_mc_plots(sl_dm, make_config_dm(sl_dm, wgtstr_dm), filter_list=[f'fj_x_{ptlab}', f'fj_x_sfBDT>{bdt_cent:.3f}'], prefix='mg_ptwgt')\n",
    "    \n",
    "#     ## 3. With Herwig sample list\n",
    "#     wgtstr_dm = f'genWeight*xsecWeight*puWeight*{lumi[year]}*fj_x_htwgt_herwig'\n",
    "#     sl_dm = ['subst_qcd-herwig-noht', 'subst_top-noht', 'subst_v-qq-noht', 'jetht-noht']\n",
    "#     make_data_mc_plots(sl_dm, make_config_dm(sl_dm, wgtstr_dm), filter_list=[f'fj_x_{ptlab}', 'fj_x_sfBDT>0.5'], prefix='herwig')\n",
    "#     make_data_mc_plots(sl_dm, make_config_dm(sl_dm, wgtstr_dm), filter_list=[f'fj_x_{ptlab}', f'fj_x_sfBDT>{bdt_cent:.3f}'], prefix='herwig')\n",
    "#     make_data_mc_plots(sl_dm, make_config_dm(sl_dm, wgtstr_dm), filter_list=[f'fj_x_{ptlab}', f'fj_x_sfBDT>{bdt_cent:.3f}', f\"{config['tagger']['var']}>{tagger_wp[-1]}\"], prefix='herwig', \n",
    "#                        g_do_kde_vars=g_do_kde_vars, g_custom_kde_bw=g_custom_kde_bw) ## also make the KDE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "# Signal/proxy comparison plots\n",
    "\n",
    "Based on the ak-array dict `arr`, The below recipe creates the proxy jet (from MC) and signal jet comparison plots on various jet observables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the signal tree\n",
    "import re\n",
    "arr['real-signal'] = NanoEventsFactory.from_root(config['main_analysis_tree']['path'].replace('$YEAR', str(year)), treepath='/'+config['main_analysis_tree']['treename'], schemaclass=BaseSchema).events()\n",
    "\n",
    "basecut_signal = config['main_analysis_tree']['selection']\n",
    "arr['real-signal'].maskdict = {}\n",
    "arr['real-signal'].maskdict['base'] = eval_expr(arr['real-signal'], basecut_signal)\n",
    "\n",
    "basesel = { # name: cut, label\n",
    "    'sv': (\"(fj_x_sj1_nsv>=1) & (fj_x_sj2_nsv>=1)\", r'$N_{SV}^{match}\\geq 1$'),\n",
    "    'tightsv': (\"((fj_x_sj1_sv1_ntracks>2) & (np.abs(fj_x_sj1_sv1_dxy)<3) & (fj_x_sj1_sv1_dlensig>4) & (fj_x_sj2_sv1_ntracks>2) & (np.abs(fj_x_sj2_sv1_dxy)<3) & (fj_x_sj2_sv1_dlensig>4))\", r'$N_{SV,tight}^{match}\\geq 1$'),\n",
    "}\n",
    "def func_basesel(name):\n",
    "    if name in basesel.keys():\n",
    "        return basesel[name]\n",
    "    elif name[:5]=='sfbdt':\n",
    "        x = float(name[5:])/1000.\n",
    "        return ('(fj_x_sfBDT>%.3f)'%x, r'$sfBDT>%.3f$'%x)\n",
    "#         return (f'(fj_x_sfBDT>-0.5*np.exp(70*(fj_x_ParticleNetMD_XbbVsQCD-1))+{x:.3f})', r'$sfBDT+0.5\\,exp(70\\,T_{xbb})>%.3f$'%x)\n",
    "#         return ('(fj_x_sfBDT_nopresel_ext_pt600_j1>%.3f)'%x, r'$sfBDT>%.3f$'%x)\n",
    "    else:\n",
    "        raise RuntimeError('Baseline cut name not recognized.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bininfo = [ #(vname, nbin, xmin, xmax, label, *vname for nominal*, xlim)   \n",
    "#     ('fj_x_pt', 40, 0, 1000, r'$p_{T}$ (AK15)', 'fj_1_pt', None),\n",
    "    ('fj_x_sdmass', 15, 50, 200, r'$m_{SD}$ (AK15)', 'fj_1_sdmass', None),\n",
    "#     ('fj_x_tau21', 20, 0, 1, r'$\\tau_{21}$ (AK15)', 'ak15_tau21', None), ##avaliable\n",
    "    \n",
    "#     ('fj_x_deltaR_sj12', 40, 0, 1.5, r'$\\Delta R_{sj_{1},sj_{2}}$ (AK15)', 'fj_1_deltaR_sj12', None),\n",
    "#     ('fj_x_pt', 40, 0, 1000, r'$p_{T}$ (AK15)', 'ak15_pt', None),\n",
    "#     ('fj_x_sj1_pt', 40, 0, 1000, r'$p_{T,sj_{1}}$ (AK15)', 'ak15_sj1_pt', None),\n",
    "#     ('fj_x_sj1_rawmass', 40, 0, 200, r'$m_{sj_{1},raw}$ (AK15)', 'ak15_sj1_rawmass', None), ##avaliable\n",
    "#     ('fj_x_sj2_pt', 40, 0, 1000, r'$p_{T,sj_{2}}$ (AK15)', 'ak15_sj2_pt', None),\n",
    "#     ('fj_x_sj2_rawmass', 40, 0, 200, r'$m_{sj_{2},raw}$ (AK15)', 'ak15_sj2_rawmass', None), ##avaliable\n",
    "    \n",
    "#     ('fj_x_nsv', 10, 0, 10, r'$N_{SV}$ (AK15)', 'ak15_nlooseSV', None), ##avaliable\n",
    "#     ('fj_x_nsv_ptgt25', 8, 0, 8, r'$N_{SV,p_{T}\\geq 25}$ (AK15)', 'ak15_nlooseSV_ptgt25', None), ##avaliable\n",
    "#     ('fj_x_nsv_ptgt50', 8, 0, 8, r'$N_{SV,p_{T}\\geq 50}$ (AK15)', 'ak15_nlooseSV_ptgt50', None), ##avaliable\n",
    "#     ('fj_x_ntracks', 20, 0, 20, r'$N_{tracks}$ (AK15)', 'ak15_nlooseSV_ntracks', None), ##avaliable\n",
    "#     ('fj_x_ntracks_sv12', 20, 0, 20, r'$N_{tracks\\;for\\;SV_{1,2}}$ (AK15)', 'ak15_nlooseSV_ntracks_sv12', None), ##avaliable\n",
    "#     ('fj_x_sj1_nsv', 20, 0, 20, r'$N_{SV\\;from\\;sj_{1}}$ (AK15)', 'ak15_sj1_nlooseSV', None), ##avaliable\n",
    "#     ('fj_x_sj1_ntracks', 20, 0, 20, r'$N_{tracks\\;from\\;sj_{1}}$ (AK15)', 'ak15_sj1_nlooseSV_ntracks', None), ##avaliable\n",
    "#     ('fj_x_sj1_sv1_pt', 20, 0, 200, r'$p_{T,\\;SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_pt', None),\n",
    "#     ('fj_x_sj1_sv1_mass', 20, 0, 50, r'$m_{SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_mass', None), ##avaliable\n",
    "#     ('fj_x_sj1_sv1_masscor', 20, 0, 50, r'$m_{cor\\;for\\;SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_masscor', None),\n",
    "#     ('fj_x_sj1_sv1_ntracks', 20, 0, 20, r'$N_{tracks\\;from\\;SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_ntracks', None),\n",
    "#     ('fj_x_sj1_sv1_dxy', 20, 0, 5, r'$d_{xy,\\;SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_dxy', None),\n",
    "#     ('fj_x_sj1_sv1_dxysig', 20, 0, 20, r'$\\sigma_{d_{xy},\\;SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_dxysig', None),\n",
    "#     ('fj_x_sj1_sv1_dlen', 20, 0, 5, r'$d_{z,\\;SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_dlen', None),\n",
    "#     ('fj_x_sj1_sv1_dlensig', 20, 0, 20, r'$\\sigma_{d_{z},\\;SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_dlensig', None),\n",
    "#     ('fj_x_sj1_sv1_chi2ndof', 20, 0, 5, r'$\\chi^2 / Ndof_{SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_chi2ndof', None),\n",
    "#     ('fj_x_sj1_sv1_pangle', 40, 0, 5, r'$pAngle_{SV_{1}\\;in\\;sj_{1}}$ (AK15)', 'ak15_sj1_looseSV_pangle', None),\n",
    "]\n",
    "bininfo += [\n",
    "    (config['tagger']['var'], 50, 0, 1, config['tagger']['var'].replace('fj_x_',''), config['main_analysis_tree']['tagger'], None),\n",
    "#     ((config['tagger']['var']+'_WP', config['tagger']['var']), 50, 0, 1, config['tagger']['var'].replace('fj_x_',''), config['main_analysis_tree']['tagger'], None),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dirname = config['routine_name']+'_sigpxy'\n",
    "if not os.path.exists(f'plots/{g_dirname}_{year}'):\n",
    "    os.makedirs(f'plots/{g_dirname}_{year}')\n",
    "\n",
    "## Make comparison plots for normal weight (MC adopt the same weight as in the fit), or for additional mass / pT / tau21 weight\n",
    "# for wgtfac, pfwgt in zip(['1','massdatamcwgt','ptdatamcwgt'], ['nom', 'massdatamcwgt', 'ptdatamcwgt']):\n",
    "for wgtfac, pfwgt in zip(['1'], ['nom']):\n",
    "\n",
    "    wgtstr = f'genWeight*xsecWeight*puWeight*fj_x_htwgt*{wgtfac}'\n",
    "    wgtstr_signal = config['main_analysis_tree']['weight']\n",
    "\n",
    "    mpl.rcParams['axes.prop_cycle'] = cycler(color=['blue', 'red', 'green', 'violet', 'darkorange', 'black', 'cyan', 'yellow'])\n",
    "    do_rwgt = 0\n",
    "    for ptmin, ptmax in config['pt_range']['range']:\n",
    "        ptlab = f'pt{ptmin}to{ptmax}'\n",
    "        presel, presel1 = f'(fj_x_pt>{ptmin}) & (fj_x_pt<{ptmax})', f\"({config['main_analysis_tree']['pt_var']}>={ptmin}) & ({config['main_analysis_tree']['pt_var']}<{ptmax})\"\n",
    "        label = {'proxy': f\"g({config['type']})\", 'real-signal':config['main_analysis_tree']['label']}\n",
    "                \n",
    "        for vname, nbin, xmin, xmax, vlabel, vname1, xlim in bininfo:\n",
    "            if not isinstance(vname, str): ## savename is specified other then the variable name\n",
    "                savename, vname = vname\n",
    "            else:\n",
    "                savename = vname\n",
    "            if not isinstance(nbin, int):\n",
    "                edges, xmin, xmax, nbin = nbin, min(nbin), max(nbin), len(nbin)\n",
    "            else:\n",
    "                edges = np.linspace(xmin, xmax, nbin+1)\n",
    "\n",
    "            f, ax = plt.subplots(figsize=(12,12))\n",
    "            hep.cms.label(data=False, paper=False, year=year, ax=ax, rlabel=r'%s $fb^{-1}$ (13 TeV)'%lumi[year], fontname='sans-serif')\n",
    "            \n",
    "            ## Signal jet\n",
    "            for sam in ['real-signal']:\n",
    "                arr[sam].maskdict['_tmp_sigpxy_presel'] = eval_expr(arr[sam], presel1)\n",
    "                _content = concat_array(arr, expr=vname1, sam_list=sam, filter_list=['base', '_tmp_sigpxy_presel'])\n",
    "                _weights = concat_array(arr, expr=wgtstr_signal, sam_list=sam, filter_list=['base', '_tmp_sigpxy_presel'])\n",
    "                h = get_hist(_content, bins=edges, weights=_weights)\n",
    "                plot_hist(h, bins=edges, label=label[sam]+' $N_{SV}^{match}\\geq 1$' if sam=='qcd-mg' else label[sam], normed=True)\n",
    "\n",
    "            ## Proxy jet\n",
    "            use_standard_sfbdt = False  # if True, use standard sfBDT variation list for plot: [0.5, 0.8, 0.9, 0.95]\n",
    "            proxy_sl = ['subst_qcd-mg-noht', 'subst_top-noht', 'subst_v-qq-noht']\n",
    "            if use_standard_sfbdt:\n",
    "                selclist, suf_label = ['sv+sfbdt500', 'sv+sfbdt800', 'sv+sfbdt900', 'sv+sfbdt950'], ['','','','']\n",
    "            else:\n",
    "                bdt_seq = arr[f\"bdt_seq_{config['pt_range']['name']}__{config['main_analysis_tree']['name']}\"][(ptmin,ptmax)]\n",
    "                selclist = ['sv+sfbdt500'] + [f'sv+sfbdt{int(b*1000)}' for b in [bdt_seq[0], bdt_seq[int((len(bdt_seq)-1)/2)], bdt_seq[-1]]]\n",
    "                suf_label = ['', ' (lower)', ' (central)', ' (upper)']\n",
    "            selclist, suf_label = ['sv+sfbdt500', 'sv+sfbdt800', 'sv+sfbdt900', 'sv+sfbdt950'], ['','','','']\n",
    "            for ext, slb in zip(selclist, suf_label):\n",
    "                cutstr = ' & '.join(list(filter(None, [presel]+[func_basesel(cname)[0] for cname in ext.split('+')]))) ## join the cut string\n",
    "                for sam in proxy_sl:\n",
    "                    for i in '12':\n",
    "                        arr[sam].maskdict[f'_tmp_fj_{i}_sigpxy_{ext}'] = eval_expr(arr[sam], cutstr.replace('fj_x', f'fj_{i}'))\n",
    "                        if f'fj_x_{ptlab}' not in arr[sam].maskdict:\n",
    "                            arr[sam].maskdict[f'fj_{i}_{ptlab}'] = eval_expr(arr[sam], f'(fj_{i}_pt>={ptmin}) & (fj_{i}_pt<{ptmax})')\n",
    "                        if any([m not in arr[sam].maskdict for m in [f'fj_{i}_flvB', f'fj_{i}_flvC', f'fj_{i}_flvL']]):\n",
    "                            arr[sam].maskdict[f'fj_{i}_flvB'] = eval_expr(arr[sam], f'fj_{i}_nbhadrons>=1')\n",
    "                            arr[sam].maskdict[f'fj_{i}_flvC'] = eval_expr(arr[sam], f'(fj_{i}_nbhadrons==0) & (fj_{i}_nchadrons>=1)')\n",
    "                            arr[sam].maskdict[f'fj_{i}_flvL'] = eval_expr(arr[sam], f'(fj_{i}_nbhadrons==0) & (fj_{i}_nchadrons==0)')\n",
    "                _content = concat_array_fj12(arr, expr=vname, sam_list=proxy_sl, filter_list=['fj_x_base', f\"fj_x_flv{config['type'][0].upper()}\", f'fj_x_{ptlab}', f'_tmp_fj_x_sigpxy_{ext}'])\n",
    "                _weights = concat_array_fj12(arr, expr=wgtstr, sam_list=proxy_sl, filter_list=['fj_x_base', f\"fj_x_flv{config['type'][0].upper()}\", f'fj_x_{ptlab}', f'_tmp_fj_x_sigpxy_{ext}'])\n",
    "                h = get_hist(_content, bins=edges, weights=_weights)\n",
    "                plot_hist(h, bins=edges, label=label['proxy']+' '+(rwgt_ext_label if do_rwgt else '')+' & '.join([func_basesel(cname)[1] for cname in ext.split('+')])+slb, normed=True)\n",
    "\n",
    "            ax.legend()\n",
    "            ax.set_xlim((xmin, xmax) if xlim is None else xlim)\n",
    "            ax.set_xlabel(vlabel, ha='right', x=1.0); ax.set_ylabel('A.U.', ha='right', y=1.0); \n",
    "            print('save plot: ', f'plots/{g_dirname}_{year}/{pfwgt}_{presel}__{savename}.png/pdf')\n",
    "            plt.savefig(f'plots/{g_dirname}_{year}/{pfwgt}_{presel}__{savename}.png')\n",
    "            plt.savefig(f'plots/{g_dirname}_{year}/{pfwgt}_{presel}__{savename}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "# Other comparisons\n",
    "\n",
    "The below function enables one to make a simple comparison with the given sample lists, weight strings, pre-selection strings, and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_comp_plot(arr, bininfo, sam_list, wgtstr, base_mask, presel, label, isnormed=True):\n",
    "    for i in range(len(sam_list)):\n",
    "        if isinstance(sam_list[i], str):\n",
    "            sam_list[i] = [sam_list[i]]\n",
    "    for i in range(len(base_mask)):\n",
    "        if isinstance(base_mask[i], str):\n",
    "            base_mask[i] = [base_mask[i]]\n",
    "    \n",
    "    mpl.rcParams['axes.prop_cycle'] = cycler(color=['blue', 'red', 'green', 'violet', 'darkorange', 'black', 'cyan', 'yellow'])\n",
    "    for vname, nbin, xmin, xmax, vlabel in bininfo:\n",
    "        if not isinstance(vname, str): ## savename is specified other then the variable name\n",
    "            savename, vname = vname\n",
    "        else:\n",
    "            savename = vname\n",
    "        if not isinstance(nbin, int):\n",
    "            edges, xmin, xmax, nbin = nbin, min(nbin), max(nbin), len(nbin)\n",
    "        else:\n",
    "            edges = np.linspace(xmin, xmax, nbin+1)\n",
    "\n",
    "        f, ax = plt.subplots(figsize=(12,12))\n",
    "        hep.cms.label(data=False, paper=False, year=year, ax=ax, rlabel=r'%s $fb^{-1}$ (13 TeV)'%lumi[year], fontname='sans-serif')\n",
    "\n",
    "        for sl, wgt, bmask, sel, lab in zip(sam_list, wgtstr, base_mask, presel, label):\n",
    "            for sam in sl:\n",
    "                for i in '12':\n",
    "                    arr[sam].maskdict[f'_tmp_fj_{i}_simple_comp'] = eval_expr(arr[sam], sel.replace('fj_x',f'fj_{i}'))\n",
    "            _content = concat_array_fj12(arr, expr=vname, sam_list=sl, filter_list=bmask+['_tmp_fj_x_simple_comp'])\n",
    "            _weights = concat_array_fj12(arr, expr=wgt, sam_list=sl, filter_list=bmask+['_tmp_fj_x_simple_comp']) if wgt!='1' else ak.ones_like(_content)\n",
    "#             print(_content, _weights)\n",
    "            h = get_hist(_content, bins=edges, weights=_weights)\n",
    "            plot_hist(h, bins=edges, label=lab, normed=isnormed)\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        ax.set_xlabel(vlabel, ha='right', x=1.0); ax.set_ylabel('A.U.' if isnormed else 'Events / bin', ha='right', y=1.0); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard vs. extra b-enriched sample comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bininfo = [ #(savename, vname, nbin, xmin, xmax, label)\n",
    "    ('fj_x_btagcsvv2', [0,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.98,0.99,0.995,1], None, None, r'$CSVv2$'),\n",
    "    ('fj_x_mSV12_ptmax_log', [-0.4,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,2.5,3.2,3.9], None, None, r'$log(m_{SV1,p_{T}\\,max}\\; /GeV)$'),\n",
    "    ('fj_x_mSV12_dxysig_log', [-0.8,-0.4,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,2.5,3.2], None, None, r'$log(m_{SV1,d_{xy}sig\\,max}\\; /GeV)$'),\n",
    "]\n",
    "ptmin, ptmax = 250, 350\n",
    "simple_comp_plot(\n",
    "    arr=arr, bininfo=bininfo,\n",
    "    sam_list=[['subst_qcd-mg-noht'],['subst_qcd-mg-bflav-noht']],\n",
    "    wgtstr=['genWeight*xsecWeight*puWeight*fj_x_htwgt', 'genWeight*xsecWeight*puWeight*fj_x_htwgt*fj_x_bflav_htwgt'],\n",
    "    base_mask=['fj_x_base']*2,\n",
    "    presel=[f'(fj_x_nbhadrons>=1) & (fj_x_pt>{ptmin}) & (fj_x_pt<{ptmax}) & (fj_x_sfBDT>0.9)']*2,\n",
    "    label=['standard','b-flavor'],\n",
    "    isnormed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QCD Pythia vs. Herwig sample comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bininfo = [\n",
    "    (config['tagger']['var'], 100, 0, 1, config['tagger']['var'].replace('fj_x_','')),\n",
    "]\n",
    "simple_comp_plot(\n",
    "    arr=arr, bininfo=bininfo,\n",
    "    sam_list=[['subst_qcd-mg-noht'],['subst_qcd-herwig-noht']],\n",
    "    wgtstr=['genWeight*xsecWeight*puWeight*fj_x_htwgt', 'genWeight*xsecWeight*puWeight*fj_x_htwgt_herwig'],\n",
    "    base_mask=['fj_x_base']*2,\n",
    "    presel=[f'(fj_x_nbhadrons>=1) & (fj_x_sfBDT>0.95) & (fj_x_pt>800) ']*2,\n",
    "    label=['Pythia','Herwig'],\n",
    "    isnormed=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "# Check systematic templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def set_sns_color(*args):\n",
    "    sns.palplot(sns.color_palette(*args))\n",
    "    sns.set_palette(*args)\n",
    "\n",
    "set_sns_color('cubehelix_r', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = config['year']\n",
    "lumi = {2016: 35.92, 2017: 41.53, 2018: 59.74}\n",
    "\n",
    "bininfo_dm = [ # vtitlecontains, bins, xmin, xmax, vlabel\n",
    "    # v2\n",
    "    (\"csvv2_var22binsv2\", [0,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.98,0.99,0.995,1], None, None, r'$CSVv2$'),\n",
    "    (\"csvv2_var20binsv2\", [0,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.98,1], None, None, r'$CSVv2$'),\n",
    "    ('msv12_ptmax_log_var22binsv2', [-0.4,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,2.5,3.2,3.9], None, None, r'$log(m_{SV1,p_{T}\\,max}\\; /GeV)$'),\n",
    "#     ('msv12_dxysig_log_var22binsv2', [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8], None, None, r'$log(m_{SV1,d_{xy}sig\\,max}\\; /GeV)$'),\n",
    "    ('msv12_dxysig_log_var22binsv2', [-0.8,-0.4,0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,2.5,3.2], None, None, r'$log(m_{SV1,d_{xy}sig\\,max}\\; /GeV)$'),\n",
    "]\n",
    "\n",
    "if config['type'] == 'cc':\n",
    "    color_order, cat_order = sns.color_palette('cubehelix_r', 3), ['flvL','flvB','flvC']\n",
    "else:\n",
    "    color_order, cat_order = np.array(sns.color_palette('cubehelix_r', 3))[[1,0,2]], ['flvL','flvC','flvB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stacked_plots_for_shapeunc(inputdir, unce_type=None, plot_unce=True, draw_stacked_plots=False, save_unce_comp_plots=True, show_plots=True, norm_unce=False):\n",
    "    r\"\"\"Make the shape comparison and/or the stacked histograms for a specific type of shape uncertainty based on the fitDiagnostics.root\n",
    "    \n",
    "    Arguments:\n",
    "        inputdir: Directory to fitDiagnostics.root\n",
    "        unce_type: Name of shape uncertainty (w/o Up or Down) to plot.\n",
    "        plot_unce: If or not plot the MC uncertainty in the upper & lower panel. Default: True\n",
    "        draw_stacked_plots: If or not also draw the stacked histograms (drawing the comparison plots is the default option). Default: False\n",
    "        save_unce_comp_plots: If or not store the shape comparison plot. Default: True\n",
    "        show_plots: If or not show plot in the runtime. Default: True\n",
    "        norm_unce: Normalize the up/down uncertainty to nominal. Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    year = 2016 if 'SF2016' in inputdir else 2017 if 'SF2017' in inputdir else 2018 if 'SF2018' in inputdir else None\n",
    "    for vname, nbin, xmin, xmax, vlabel in bininfo_dm:\n",
    "        if vname in inputdir:\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError('Bininfo not found')\n",
    "    import os\n",
    "    if not isinstance(unce_type, str) or not os.path.exists(f'{inputdir}/{unce_type}Up') or not os.path.exists(f'{inputdir}/{unce_type}Down'):\n",
    "        raise RuntimeError('Uncertainty type not exist')\n",
    "\n",
    "    if not isinstance(nbin, int):\n",
    "        edges, xmin, xmax, nbin = nbin, min(nbin), max(nbin), len(nbin)\n",
    "    else:\n",
    "        edges = np.linspace(xmin, xmax, nbin+1)\n",
    "    print(inputdir, '--unce--', unce_type)\n",
    "    \n",
    "    # curves for unce\n",
    "    for b in ['pass', 'fail']:\n",
    "        content = [uproot3.open(f'{inputdir}/nominal/inputs_{b}.root')[f'{cat}'].allvalues[1:-1] for cat in cat_order[::-1]]\n",
    "        yerror  = [np.sqrt(uproot3.open(f'{inputdir}/nominal/inputs_{b}.root')[f'{cat}'].allvariances[1:-1]) for cat in cat_order[::-1]]\n",
    "        content_up   = [uproot3.open(f'{inputdir}/{unce_type}Up/inputs_{b}.root')[f'{cat}_{unce_type}Up'].allvalues[1:-1] for cat in cat_order[::-1]]\n",
    "        content_down = [uproot3.open(f'{inputdir}/{unce_type}Down/inputs_{b}.root')[f'{cat}_{unce_type}Down'].allvalues[1:-1] for cat in cat_order[::-1]]\n",
    "        lab_suf = ''\n",
    "        if norm_unce:\n",
    "            lab_suf = '(norm)'\n",
    "            for icat, cat in enumerate(cat_order[::-1]):\n",
    "                content_up[icat] *= content[icat].sum() / content_up[icat].sum()\n",
    "                content_down[icat] *= content[icat].sum() / content_down[icat].sum()\n",
    "        f, ax = plt.subplots(figsize=(12,12))\n",
    "        hep.cms.label(data=True, paper=False, year=year, ax=ax, rlabel=r'%s $fb^{-1}$ (13 TeV)'%lumi[year], fontname='sans-serif')\n",
    "        for icat, (cat, color) in enumerate(zip(cat_order[::-1], ['blue', 'red', 'green'])):\n",
    "            hep.histplot(content[icat], yerr=yerror[icat], bins=edges, label=f'QCD ({cat})', color=color)\n",
    "        for icat, (cat, color) in enumerate(zip(cat_order[::-1], ['blue', 'red', 'green'])):\n",
    "            hep.histplot(content_up[icat], bins=edges, label=f'QCD ({cat}) {unce_type}Up {lab_suf}', color=color, linestyle='--')\n",
    "        for icat, (cat, color) in enumerate(zip(cat_order[::-1], ['blue', 'red', 'green'])):\n",
    "            hep.histplot(content_down[icat], bins=edges, label=f'QCD ({cat}) {unce_type}Down {lab_suf}', color=color, linestyle=':')\n",
    "        ax.set_xlim(xmin, xmax); ax.set_xlabel(vlabel, ha='right', x=1.0); ax.set_ylabel('Events / bin', ha='right', y=1.0)\n",
    "        ax.legend(prop={'size': 18})\n",
    "        \n",
    "        if save_unce_comp_plots:\n",
    "            plt.savefig(f'{inputdir}/unce_comp_{unce_type}_{b}.png')\n",
    "            plt.savefig(f'{inputdir}/unce_comp_{unce_type}_{b}.pdf')\n",
    "            if not show_plots:\n",
    "                plt.close()\n",
    "\n",
    "    # stacked plots\n",
    "    if draw_stacked_plots:\n",
    "        for filedir in ['nominal', unce_type+'Up', unce_type+'Down']:\n",
    "            roothist_suf = '' if filedir=='nominal' else '_'+filedir\n",
    "            for b in ['pass', 'fail']:\n",
    "                set_sns_color(color_order)\n",
    "                f = plt.figure(figsize=(12,12))\n",
    "                gs = mpl.gridspec.GridSpec(2, 1, height_ratios=[3, 1], hspace=0.05) \n",
    "                ax = f.add_subplot(gs[0])\n",
    "                hep.cms.label(data=True, paper=False, year=year, ax=ax, rlabel=r'%s $fb^{-1}$ (13 TeV)'%lumi[year], fontname='sans-serif')\n",
    "                ax.set_xlim(xmin, xmax); ax.set_xticklabels([]); \n",
    "                ax.set_ylabel('Events / bin', ha='right', y=1.0)\n",
    "                label, hdm = {}, {}\n",
    "                underflow = False if vlabel[-2:] in ['-u','-a'] else True\n",
    "                overflow  = False if vlabel[-2:] in ['-o','-a'] else True\n",
    "                if vlabel[-2:] in ['-u','-o','-a']:\n",
    "                    vlabel = vlabel[:-2]\n",
    "\n",
    "                content = [uproot3.open(f'{inputdir}/{filedir}/inputs_{b}.root')[f'{cat}{roothist_suf}'].allvalues[1:-1] for cat in cat_order]\n",
    "                bkgtot = np.sum(content, axis=0)\n",
    "                hep.histplot(content, bins=edges, label=[f'QCD ({cat})' for cat in cat_order], histtype='fill', edgecolor='k', linewidth=1, stack=True) ## draw MC\n",
    "                data = uproot3.open(f'{inputdir}/nominal/inputs_{b}.root')['data_obs'].allvalues[1:-1]\n",
    "                data_errh = data_errl = np.sqrt(uproot3.open(f'{inputdir}/nominal/inputs_{b}.root')['data_obs'].allvariances[1:-1])\n",
    "                hep.histplot(data, yerr=(data_errl, data_errh), bins=edges, label='Data', histtype='errorbar', color='k', markersize=15, elinewidth=1.5) ## draw data\n",
    "                ax.set_ylim(0, ax.get_ylim()[1])\n",
    "                ax.legend()\n",
    "\n",
    "                ax1 = f.add_subplot(gs[1]); ax1.set_xlim(xmin, xmax); ax1.set_ylim(0.001, 1.999)\n",
    "                ax1.set_xlabel(vlabel, ha='right', x=1.0); ax1.set_ylabel('Data / MC', ha='center')\n",
    "                ax1.plot([xmin,xmax], [1,1], 'k'); ax1.plot([xmin,xmax], [0.5,0.5], 'k:'); ax1.plot([xmin,xmax], [1.5,1.5], 'k:')\n",
    "\n",
    "                hep.histplot(data/bkgtot, yerr=(data_errl/bkgtot, data_errh/bkgtot), bins=edges, histtype='errorbar', color='k', markersize=15, elinewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ====== config me! ======\n",
    "inputdir = '/home/pku/licq/hcc/new/results/20210412_bb_M120_SF2018_pnV02bb_-val_pt-_HP_msv12_dxysig_log_var22binsv2/Cards/pt400to500/bdt968/'\n",
    "unce_type = 'pu'\n",
    "## ========================\n",
    "\n",
    "make_stacked_plots_for_shapeunc(inputdir, unce_type=unce_type, save_unce_comp_plots=False, draw_stacked_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
